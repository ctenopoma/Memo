# コーディングAIの適用

## 事業的課題

### 状況

- レガシーコードが多くある
- 仕様書の無いコードが多くある
- テストコードが存在しない、または機能していない

### 生じている課題

1. 古い言語で開発できる人がいないため、手動での修正・維持が困難である
2. 既存コードを理解している人がおらず、影響範囲が見えないため機能追加が容易ではない
3. コードから仕様を逆算する必要があり、工数がかかる
4. 過去プロジェクトの資産が密結合で埋没しており、新規開発で部品として再利用できない

### 求められる技術

1. 生成AIを用いた **「現行挙動を担保するテストケースの作成」** → レガシーコードで実現できていることの担保
2. 生成AIを用いた **「仕様のドキュメント化（仕様書作成）」** → レガシーコードを参照可能な情報に
3. 生成AIを用いた保守性の高いコードへのリファクタリング **（およびモダン言語への移行）** → 保守性の確保
4. 生成AIを用いた **「既存コードからのロジック抽出」** と機能開発 → 生成AIを用いた効率的な開発の実現

### 求められる技術に対する懸念点

1. レガシーコードをもとにしたテストの存在意義
   - 問題点：テストはレガシーコードの挙動が正解となる → バグを温存する可能性がある。このテストは仕様の正しさではなく、旧コードと新コードの仕様変化を検知するセンサであるとの認識が必要。
   - 対策：正しい仕様に対するテストは人が要件定義する必要がある。具体的にはレガシーコードから生成されるテストに追加するテスト要件を検討する。
2. 言語間のGAP
   - 問題点：旧コードをベースに作成したテストは、新コードでは実行できない
   - 対策：レガシーコードの仕様（内部ロジック）を翻訳するだけでなく、「実際の入出力データ（Input/Output）」をレガシーシステムから抽出し、それを正解データとして新コードで実行検証する（言語に依存しないブラックボックステストを実施する）。
3. ドキュメントの陳腐化
   - 問題点：リファクタリングが進むうちに仕様書が陳腐化する。
   - 対策：実装すると同時に、コードから生成・参照される動的なナレッジベースとなるように仕様書を作成する仕組みとする。
4. 非機能要件の維持・評価の困難性
   - 問題点：リファクタリングにより計算速度などの性能が劣化するリスクがある
   - 対策①：言語移行によるリスクを人であらかじめ評価しておく
   - 対策②：リファクタリング→性能評価→修正のサイクルをAI駆動で実行し、改善を図る

## 技術的な課題

SDDを用いたシステム開発を検討したが、以下の課題が見つかっている。

- ローカルLLMを用いる場合のトークン長の制限
  - 既存コードや依存ライブラリとの矛盾
  - 一度に調査、実装できるコードの範囲（階層）の限界
  - コーディングルールやユーザー指示の消失

- ハルシネーションによるロジック、テスト、デバックの誤り
  - 存在しないライブラリの利用
  - 要件を満たさない実装
  - テスト要件を満たさないテストコード
  - デバック時の誤った原因・修正案の提示

- 人間によるレビューが困難
  - 影響：AIが書いたコードが誰も理解できず、レガシーコードを再生産してしまう
  - 人：AIの実装意図が理解できない、評価者の当事者意識の希薄化
  - 機械：AIの実装速度に対して人間のレビュー速度が間に合わない
  - 方法：更新範囲が広大でDiff肥大化、コメント漏れ、レビュー基準・プロセスの曖昧さ
  - 材料：要件定義の不足、既存コードの複雑さ、AIのドメイン知識不足

追加で、レガシーコードに対するSDDの適用を考えると、導入ハードルがある。

- コードから仕様を抽出する精度
  - SDDを行うために、正確な仕様がレガシーコードから抽出できるか未知数である
  - 複雑な依存関係を読み解けるかはLLMの推論能力に依存してしまう。

### 技術的な課題に対する解決策

1. AIが実装可能な最小単位を明らかにする
   - AIが一度に扱えるコードの範囲・単位を明らかにする
   - その単位をSDDで開発することで、成果物の品質を確保する
   - その単位で分析することで、正確な実装仕様を把握する
2. 人がレビュー可能な最小単位を明らかにする
   - 人がレビュー可能なコードの範囲・単位の切り分け方を明らかにする
   - その単位で実装させ、コード、テストコードをレビューする
   - その単位で分析させ、コードの仕様を理解する
3. コードの構造・内容をグラフRAGで参照可能なDBに登録する
   - LLMの既存コードの参照を可能にする
   - トークンの無駄な消費を抑制する
   - 仕様を参照できるようになり、ハルシネーションを抑制する
   - 人のレビュー時の質問に回答できるようになる

### 解決策における懸念点

1. 解析（Parsing）とコンテキスト抽出の難易度
   - 問題点：レガシーコード（特に動的型付け言語や、GOTO文が多い古い言語）は、静的解析ツールで構文木（AST）を作れないことが多く、「正確にノード化・チャンク化（分割）できない」。
   - 対策①：耐障害性の高い（Error-tolerant）パーサーの採用

        - 手法: 厳密なコンパイルレベルの解析ではなく、文法エラーがあっても構造を推測できる「Tree-sitter」などの耐障害性パーサーや、正規表現ベースの「ファジー解析」を併用する。

        - 効果: 完全なASTが作れなくても、「ここは関数の始まりと終わりである」というブロック構造さえ特定できれば、最低限のチャンク化は可能となる。

    - 対策②：LLMによる「セマンティック・チャンキング（意味的分割）」

        - 手法: 静的解析で構造化できないスパゲッティコードに対しては、コードをテキストとしてLLMに読み込ませ、「意味のある処理ブロックごとに分割し、要約せよ」と指示を出す。

        - 効果: 構文上の区切り（{}やEnd Sub）が曖昧でも、文脈（Context）に基づいて論理的な単位でコードを切り出すことができる。

    - 対策③：ハイブリッドグラフの構築（構造＋意味）

        - 手法: 「関数呼び出し（Call Graph）」のような明示的な依存関係（静的解析）だけに頼らない。コード内の変数名、コメント、ロジックの類似性をベクトル化し、「意味的に近いコード」をエッジで結ぶ（Vector Similarity）。

        - 効果: GOTO文や動的参照（evalなど）で追えない依存関係であっても、意味的な関連性から関連コードをRAGで抽出可能にする。

2. 隠れた依存関係（Side Effects）による「最小単位」の破綻
    - 問題点: グローバル変数、DBのストアドプロシージャ、シングルトン、外部ファイルへの書き込みなど、コードの見た目（静的解析）には現れない「隠れた副作用（Side Effects）」を大量に含んでいる。 切り出されたコードだけを見てリファクタリングすると、これらの副作用が断ち切られ、システム全体として整合性が取れなくなる。
    - 対策①： **ダイナミック・トレーシング**: 静的解析だけでなく、実際の実行ログ（トレースログ）から依存関係を抽出する手法を併用し、隠れた結合を可視化する。
    - 対策②： **コンテキスト注入**: AIへのプロンプトに、対象コードだけでなく「参照しているグローバル変数リスト」や「DBスキーマ定義」を強制的にコンテキストとして含めるルールを作る。

3. GraphRAGの同期レイテンシと整合性
    - 問題点: コードの変更頻度に対してDBの更新が追いつかないリスクがある。 AIが古い情報を参照すると、修正前の仕様に基づいて新しいコードを提案してしまう
    - 対策①： **差分更新**: 全文再解析ではなく、GitのDiffがあったファイルとその影響範囲のみをグラフDB上で更新するパイプラインを構築する。
    - 対策②： **バージョニング**: GraphDB内のノードにGitコミットハッシュを紐付け、AIが検索する際は必ず「現在のHEAD」に対応する情報を参照するようにクエリを制限する。

4. 「正解を知る人間（Oracle）」の不在がボトルネック化
    - 問題点: レガシーシステムの「仕様」はドキュメントではなく、現行システムの挙動そのものになっていることが多く、正解の挙動を確認するのに時間を要する。
    - 対策：リファクタリングにおけるテスト範囲をあらかじめ定義する。無理にシステム全体の検証を行わず、現行システムと同じ動作を最低目標とし、追加でどこまで検証するかを検討する。

## 実施事項

1. AI・人が扱える「処理単位（Unit）」の策定
レガシーコードを見る前に、まず「扱える基準（スペック）」を定義する。
    - AIの単位: ローカルLLM/クラウドLLMのトークン制限、推論精度が維持できるコンテキスト量（例: 1ファイル500行以内、依存関数深度3以内）。
    - 人の単位: レビュー可能な認知負荷の限界（例: 1回のプルリクエストで200行以内、単一責任の原則に基づく機能単位）。
2. レガシーコードの「セグメンテーション（切り出し）」戦略の策定：定義した「単位」を、巨大で密結合なレガシーコードに当てはめ、切り分けるための戦略を決める。
    - ギャップ分析: 定義した単位を超過している「巨大クラス・関数」を特定する。
    - 切断箇所の特定: 依存関係解析（静的・動的）を行い、どこで切れば「AI/人が扱える単位」に収まるか、疎結合にできる「縫い目（Seams）」を見つける。
3. コード構造と仕様の「Living GraphRAG」構築:切り分けた単位（または切り分けるための構造情報）をDB化する。
    - 構造化: コードの依存関係と、手順2で特定した「論理的な区切り」をグラフDBに格納する。
    - 動的同期: コード修正に伴い、常に最新の構造と仕様解説が参照できるよう、CI/CDパイプラインに更新処理を組み込む。

4. リファクタリング・開発
    - (テスト): 切り出した単位ごとに、現行挙動を担保するテストをAIに生成させる。
    - (リファクタリング): テストで守られた単位の中で、AIを用いてリファクタリング、仕様化、機能追加を行う。
    - (資産化)：過去のレガシーコードを資産として、新システム開発に再利用する

### 開発にAI・RAGを導入する将来的なメリット

- (資産の高度化)：SPL（ソフトウェアプロダクトライン）化に向けた共通性・可変性分析の自動化
  - ベクトル検索によるクラスタリングと、Diff分析によるパラメータ抽出。
- (運用の高度化)：自己記述的な可観測性（Observability）コードの自動実装
  - AST解析による挿入箇所の特定と、OpenTelemetry等の標準規格コードの生成。
- (設計の高度化)：リバースモデリングとRTM（要件追跡マトリクス）の自動構築
  - GraphRAG上の「要件ノード」と「コードノード」の意味的リンク（エッジ）の推論・生成。
  - MBD的な要件に対する自動モデル生成、自動実装の実現

## 評価

### 技術的な評価

#### 1. AI・人が扱える単位であるかの評価

- 定義した「スペック（行数、トークン数、複雑度）」が適切だったか、実地検証します。
- 「AIには小さすぎて効率が悪い」や「人には大きすぎてレビュー漏れが起きる」が起きていないかを評価する。

| 評価の視点   | KPI（定量指標）                           | 評価基準（定性/判断基準）                                                   | 測定方法                 |
| ------------ | ----------------------------------------- | --------------------------------------------------------------------------- | ------------------------ |
| AIの処理能力 | コンテキスト溢れ発生率AIの回答完了率      | 定義した単位で投げた際、トークン不足やタイムアウトが起きずに完答できるか。  | APIエラーログの集計      |
| AIの推論精度 | 1回でのコード生成成功率(Pass@1)           | コンパイルエラーや論理破綻なく、1発で動くコードが出力される割合。           | 自動ビルド・テストの結果 |
| 人の認知負荷 | プルリク（PR）レビュー時間コメント数/行数 | 1つのPRに対し、レビュワーが理解にかかる時間が許容範囲内（例: 30分以内）か。 | PR統計データの計測       |

#### 2. レガシーコードの「セグメンテーション（切り出し）」戦略の評価

- スパゲッティコードを適切に解体できているか、構造的な改善度を評価します。
- 「無理やり切って動かなくなった」リスクと、「切り出せずに放置された領域」を可視化します。

| 評価の視点 | KPI（定量指標）                        | 評価基準（定性/判断基準）                                                                        | 測定方法                             |
| ---------- | -------------------------------------- | ------------------------------------------------------------------------------------------------ | ------------------------------------ |
| 疎結合化   | 結合度（Coupling）の推移依存方向の整理 | 切り出した単位が、外部への依存を減らし、単体でテスト可能な状態（Mock化可能）になっているか。     | 静的解析ツール                       |
| 凝集度     | LCOM（メソッドの凝集度欠如）           | 1つのクラス・単位の中に、無関係な責務が混在していないか（単一責任の原則）。                      | 静的解析ツール                       |
| 網羅性     | セグメンテーション適用率               | 全レガシーコードのうち、戦略に基づいて切り出しに成功した（または切り出し対象と特定できた）割合。 | プロジェクト管理ツールでの進捗可視化 |

#### 3. コードのRAGの評価

- 構築したナレッジベースが、開発に耐えうる精度と鮮度を持っているか評価します。
- 仕様書作成やコード理解支援において、「AIが嘘をついていないか」「情報が古くないか」を保証します。

| 評価の視点 | KPI（定量指標）            | 評価基準（定性/判断基準）                                                                          | 測定方法                                        |
| ---------- | -------------------------- | -------------------------------------------------------------------------------------------------- | ----------------------------------------------- |
| 検索精度   | Context Recall / Precision | 質問に対して、関連するコードや仕様箇所を正しくDBから抽出できているか（ノイズが含まれていないか）。 | 評価用データセット（Q&Aペア）を用いた自動テスト |
| 回答品質   | Faithfulness（誠実性）     | AIの回答が、検索されたコードの事実に基づいているか（ハルシネーションがないか）。                   | LLMによるLLM評価（LLM-as-a-Judge）              |
| 鮮度・同期 | 同期レイテンシ             | コードがCommitされてから、RAGの回答に反映されるまでの時間（例: 5分以内）。                         | CIパイプラインの実行時間計測                    |

#### 4. レガシーコードの改修・再活用に対するAI利用の評価

- 最終的な成果物（コード・資産）と、生産性への寄与を評価します。
- 「AIで作ったが、結局誰もメンテできない」「資産化したが使われなかった」という事態を防ぎ、ROI（投資対効果）を明確にします。

| 評価の視点 | KPI（定量指標）                                 | 評価基準（定性/判断基準）                                                                                                                                                                                                                    | 測定方法                             |
| ---------- | ----------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------ |
| 挙動担保   | 回帰テスト通過率                                | リファクタリング前後で、As-Isテスト（スナップショットテスト）が100%一致するか。 <br> ※フェーズ1（移行・構造化）においては、未知のバグを含めた「現行踏襲率」を正解とする。既知のバグ修正は別途要件定義を行い、フェーズ2以降で実施・評価する。 | 自動テスト実行結果                   |
| コード品質 | 保守性指数（Maintainability Index）循環的複雑度 | 改修後のコードが、人間にとって読みやすく、保守しやすい数値になっているか。                                                                                                                                                                   | 静的解析ツール                       |
| 資産化効率 | 抽出ロジックの再利用回数                        | 資産化したビジネスロジックが、実際に新システムで何箇所利用されたか。                                                                                                                                                                         | 依存関係分析参照カウント             |
| 生産性     | 工数削減率                                      | 従来の手動解析・実装と比較して、どれくらい時間短縮できたか。                                                                                                                                                                                 | 実績工数 vs 過去の類似案件の標準工数 |

### 事業的な貢献見積

#### 1. 人材課題

| 評価項目       | KPI（定量指標）                                              | 見積 | 評価方法                                                                                                                                              |
| -------------- | ------------------------------------------------------------ | ---- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| 属人性の解消度 | バス係数（Bus Factor）の向上                                 | -    | (その人がいなくなるとプロジェクトが止まる人数の減少),AI/RAG導入後、若手や別言語のエンジニアが、レガシーコードの修正タスクを完遂できた件数を測定する。 |
| 教育コスト     | オンボーディング時間(新規参画者が初コミットできるまでの期間) | -    | 従来（マニュアル読解＋OJT）と、AI（Living Documentation＋対話解説）を利用した場合の、習熟期間を比較する。                                             |
| 保守の民主化   | エンジニアカバレッジ(保守可能なエンジニアの比率)             | -    | チーム内で、そのレガシーシステムの修正を担当できるエンジニアの割合の推移を計測する。                                                                  |

#### 2. 理解・影響範囲の課題

| 評価項目     | KPI（定量指標）                                        | 見積 | 評価方法                                                                                                                                       |
| ------------ | ------------------------------------------------------ | ---- | ---------------------------------------------------------------------------------------------------------------------------------------------- |
| 調査効率     | 影響調査リードタイム(要件受領から着手までの時間)       | -    | 機能追加時の「調査フェーズ」にかかる工数を、導入前後で比較する。（例：3日→3時間に短縮など）                                                    |
| 開発効率     | リードタイム（着手からリリースまで）                   | -    | AI実装・人間によるレビューを含めた「機能追加の完了」までのトータル時間を計測し、レビュープロセスが新たなボトルネックになっていないか監視する。 |
| 安全性・品質 | デグレ（回帰バグ）発生率(変更後に既存機能が壊れた件数) | -    | GraphRAG等による影響範囲分析を用いた開発と、従来の手探り開発でのバグ発生率を比較する。                                                         |
| 見積もり精度 | 見積もり乖離率                                         | -    | 「見えない影響範囲」による手戻りが減ったかを評価するため、当初見積もり工数と実績工数の差分（予実差）を計測する。                               |

#### 3. 仕様逆算（リバースエンジニアリング）コスト

| 評価項目         | KPI（定量指標）                        | 見積 | 評価方法                                                                                                                                                  |
| ---------------- | -------------------------------------- | ---- | --------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 工数配分の変化   | コード読解時間（Reading Time）の削減率 | -    | 開発プロセスにおける「コード調査・仕様把握」の時間割合が減少したかを、工数管理データから分析する。                                                        |
| ドキュメント鮮度 | 仕様書と現行コードの一致率             | -    | ランダムに抽出した機能について、AI生成された仕様書（RAG）と実際の挙動が一致しているかを監査し、信頼性をスコアリングする。                                 |
| 質問解決速度     | 仕様確認のリードタイム                 | -    | 「この仕様どうなってる？」という疑問が発生してから、AI（RAG）を使って答えに辿り着くまでの時間を計測する（従来は有識者への問い合わせ待ち時間などを含む）。 |

#### 4. 資産活用（再利用）

| 評価項目                                         | KPI（定量指標）                                 | 見積 | 評価方法                                                                                                                                                                |
| ------------------------------------------------ | ----------------------------------------------- | ---- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 再利用による効率化                               | 新規開発の工数削減額(Cost Avoidance)            | -    | 抽出したビジネスロジックやモジュールを新規システムで利用したことで、ゼロから作る場合と比較して削減できた開発費を算出する。                                              |
| 資産化の実績                                     | コンポーネント抽出数と再利用率                  | -    | レガシーコードから独立した部品として切り出せた数と、それが実際に新プロジェクトで参照された回数を計測する。                                                              |
| 市場投入速度                                     | Time-to-Marketの短縮                            | -    | 既存の複雑な業務ロジック（税計算、契約ルール等）を再利用することで、新規サービスのリリースまでの期間がどれだけ短縮されたか評価する。                                    |
| 抽出コンポーネントの独立性スコア（結合度の低さ） | 結合度メトリクス（CBO/LCOM）の基準値クリア率    | -    | 静的解析ツールを用いて、抽出したコンポーネントの外部依存数（他クラスやグローバル変数への参照）を測定し、単体で動作可能な「ポータブルな状態」になっているか判定する。    |
| ドキュメント完備率                               | APIドキュメントカバレッジとサンプルコード付与率 | -    | 抽出された全コンポーネントの公開APIに対し、AIによる「機能説明」「入出力定義」および「利用サンプルコード」が漏れなく生成され、GraphRAGで検索可能な状態かを自動検証する。 |

#### ROIの算出

$$\text{ROI} = \frac{\text{削減された維持コスト} + \text{回避できた新規開発コスト} + \text{リスク低減価値}}{\text{AI導入・運用コスト}}$$

- 削減された維持コスト: 調査時間の短縮、ベテラン単価からの脱却
- 回避できた新規開発コスト: 資産再利用による開発費の圧縮
- リスク低減価値: デグレによる障害対応費用の削減、属人化リスクの解消
